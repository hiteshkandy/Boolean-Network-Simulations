{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIAL NETWORK INFERENCE STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA GENERATION - GT NETWORK SIM\n",
    "\n",
    "v0 = v1 AND NOT v2 <br>\n",
    "v1 = v0 OR v3 <br>\n",
    "v2 = NOT v4 <br>\n",
    "v3 = v2 OR NOT v5 <br>\n",
    "v4 = v3 AND v6 <br>\n",
    "v5 = NOT v1 OR v4 <br>\n",
    "v6 = v5 AND NOT v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state: [0 1 0 1 1 1 0]\n",
      "Trajectory shape: (50, 7)\n",
      "Trajectory:\n",
      "[[0 1 0 1 1 1 0]\n",
      " [1 1 0 0 0 1 1]\n",
      " [1 1 1 0 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]\n",
      " [0 1 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Define the update rule for each of the 7 nodes\n",
    "#    We use only the logical relations AND, OR, NOT (and their combinations\n",
    "#    like AND NOT, OR NOT) across the network.\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def update_7(state):\n",
    "    \"\"\"\n",
    "    state: 1D array of length 7 with values 0 or 1\n",
    "      indices: [v0, v1, v2, v3, v4, v5, v6]\n",
    "    returns: new_state, same shape\n",
    "    \"\"\"\n",
    "    v0, v1, v2, v3, v4, v5, v6 = state\n",
    "\n",
    "    # v0(t+1) = v1 AND (NOT v2)\n",
    "    new0 = int(v1 and not v2)\n",
    "\n",
    "    # v1(t+1) = v0 OR v3\n",
    "    new1 = int(v0 or v3)\n",
    "\n",
    "    # v2(t+1) = NOT v4\n",
    "    new2 = int(not v4)\n",
    "\n",
    "    # v3(t+1) = v2 OR (NOT v5)         # OR NOT\n",
    "    new3 = int(v2 or not v5)\n",
    "\n",
    "    # v4(t+1) = v3 AND v6             # AND\n",
    "    new4 = int(v3 and v6)\n",
    "\n",
    "    # v5(t+1) = (NOT v1) OR v4         # OR NOT\n",
    "    new5 = int((not v1) or v4)\n",
    "\n",
    "    # v6(t+1) = v5 AND (NOT v0)        # AND NOT\n",
    "    new6 = int(v5 and not v0)\n",
    "\n",
    "    return np.array([new0, new1, new2, new3, new4, new5, new6], dtype=int)\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2) Simulator\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def simulate_7(initial_state, steps=50):\n",
    "    \"\"\"\n",
    "    initial_state: array‐like of length 7 (0/1)\n",
    "    steps: number of synchronous update steps\n",
    "    returns: history, a (steps × 7) array of 0/1\n",
    "    \"\"\"\n",
    "    history = np.zeros((steps, 7), dtype=int)\n",
    "    state = np.array(initial_state, dtype=int)\n",
    "\n",
    "    for t in range(steps):\n",
    "        history[t] = state\n",
    "        state = update_7(state)\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 3) Example usage\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # pick a random initial state for the 7‐node network\n",
    "    init = np.random.randint(0, 2, size=7)\n",
    "    traj = np.array(simulate_7(init, steps=50))\n",
    "\n",
    "    print(\"Initial state:\", init)\n",
    "    print(\"Trajectory shape:\", traj.shape)   # should be (50,7)\n",
    "    print(\"Trajectory:\")\n",
    "    print(traj)  # each row is [v0,v1,…,v6] at that time step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIBNI Network Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0 = v6 AND NOT v5   \n",
      "v1 = NOT v0 OR v2   \n",
      "v2 = NOT v5 AND v1   \n",
      "v3 = NOT v0 AND v1   \n",
      "v4 = v5 AND v2   \n",
      "v5 = 0   \n",
      "v6 = v0 OR NOT v2   \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Entropy / MI routines (unchanged)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def entropy(arr):\n",
    "    n = len(arr)\n",
    "    counts = Counter(arr)\n",
    "    H = 0.0\n",
    "    for cnt in counts.values():\n",
    "        p = cnt / n\n",
    "        H -= p * math.log2(p)\n",
    "    return H\n",
    "\n",
    "def joint_entropy(arrays):\n",
    "    joint = list(zip(*arrays))\n",
    "    counts = Counter(joint)\n",
    "    H = 0.0\n",
    "    n = sum(counts.values())\n",
    "    for cnt in counts.values():\n",
    "        p = cnt / n\n",
    "        H -= p * math.log2(p)\n",
    "    return H\n",
    "\n",
    "def mutual_information(x, y):\n",
    "    return entropy(x) + entropy(y) - joint_entropy([x, y])\n",
    "\n",
    "def conditional_mutual_information(x, z, cond):\n",
    "    if isinstance(cond, np.ndarray):\n",
    "        cond = [cond]\n",
    "    H_xc  = joint_entropy([x, *cond])\n",
    "    H_cz  = joint_entropy([*cond, z])\n",
    "    H_c   = joint_entropy(cond)\n",
    "    H_xcz = joint_entropy([x, *cond, z])\n",
    "    return H_xc + H_cz - H_c - H_xcz\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# MIBNI regulator selection (unchanged)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def compute_dynamic_consistency(y, S_idx, data):\n",
    "    if len(S_idx)==0:\n",
    "        maj = Counter(y).most_common(1)[0][0]\n",
    "        return sum(y==maj)/len(y), {(): maj}\n",
    "    pats = data[:, S_idx]\n",
    "    table = {}\n",
    "    for pat in {tuple(r) for r in pats}:\n",
    "        mask = np.all(pats == pat, axis=1)\n",
    "        maj  = Counter(y[mask]).most_common(1)[0][0]\n",
    "        table[pat] = maj\n",
    "    preds = np.array([table[tuple(r)] for r in pats])\n",
    "    return np.mean(preds==y), table\n",
    "\n",
    "def MIFS(y, W_idx, data, k):\n",
    "    S = []\n",
    "    W = W_idx.copy()\n",
    "    scores = {w: mutual_information(y, data[:,w]) for w in W}\n",
    "    best = max(scores, key=scores.get)\n",
    "    S.append(best); W.remove(best)\n",
    "    while len(S)<k and W:\n",
    "        scores = { w: conditional_mutual_information(y, data[:,w], [data[:,s] for s in S]) for w in W }\n",
    "        best = max(scores, key=scores.get)\n",
    "        S.append(best); W.remove(best)\n",
    "    return S\n",
    "\n",
    "def SWAP(y, S_idx, W_idx, data):\n",
    "    E_max, _ = compute_dynamic_consistency(y, S_idx, data)\n",
    "    best_S, best_E = S_idx[:], E_max\n",
    "    improved = True\n",
    "    while improved:\n",
    "        improved = False\n",
    "        for si in list(best_S):\n",
    "            for wj in W_idx:\n",
    "                S_new = [x for x in best_S if x!=si] + [wj]\n",
    "                E_new, _ = compute_dynamic_consistency(y, S_new, data)\n",
    "                if E_new > best_E + 1e-9:\n",
    "                    best_S, best_E = S_new, E_new\n",
    "                    W_idx = [x for x in W_idx if x!=wj] + [si]\n",
    "                    improved = True\n",
    "                    break\n",
    "            if improved: break\n",
    "    return best_S, best_E\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Allowed‐logic fitting (fixed constant functions)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def fit_allowed_logic(y, pats):\n",
    "    \"\"\"\n",
    "    Given target y (n,) and pats = data[:, regs] (n,m), m<=2,\n",
    "    return (best_expr, best_fn, best_accuracy).\n",
    "    \"\"\"\n",
    "    n, m = pats.shape\n",
    "    best = (\"0\", lambda *args: np.zeros(n, dtype=int), -1.0)\n",
    "\n",
    "    # constants 0 and 1\n",
    "    for c in [0,1]:\n",
    "        fn = (lambda *args, c=c: np.full(n, c, dtype=int))\n",
    "        acc = np.mean(y == c)\n",
    "        if acc > best[2]:\n",
    "            best = (str(c), fn, acc)\n",
    "\n",
    "    # unary\n",
    "    if m == 1:\n",
    "        a = pats[:, 0]\n",
    "        for expr, fn in [(\"v\",        (lambda a: a)),\n",
    "                         (\"NOT v\",    (lambda a: 1 - a))]:\n",
    "            preds = fn(a)\n",
    "            acc   = np.mean(preds == y)\n",
    "            if acc > best[2]:\n",
    "                best = (expr, fn, acc)\n",
    "\n",
    "    # binary\n",
    "    if m == 2:\n",
    "        a, b = pats[:,0], pats[:,1]\n",
    "        candidates = [\n",
    "            (\"v1 AND v2\",     (lambda a,b: a & b)),\n",
    "            (\"v1 OR v2\",      (lambda a,b: a | b)),\n",
    "            (\"v1 AND NOT v2\", (lambda a,b: a & (1 - b))),\n",
    "            (\"NOT v1 AND v2\", (lambda a,b: (1 - a) & b)),\n",
    "            (\"v1 OR NOT v2\",  (lambda a,b: a | (1 - b))),\n",
    "            (\"NOT v1 OR v2\",  (lambda a,b: (1 - a) | b)),\n",
    "        ]\n",
    "        for expr, fn in candidates:\n",
    "            preds = fn(a, b)\n",
    "            acc   = np.mean(preds == y)\n",
    "            if acc > best[2]:\n",
    "                best = (expr, fn, acc)\n",
    "\n",
    "    return best\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Main inference (K=2) + pretty‐print\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def infer_boolean_network_restricted(data):\n",
    "    n_samples, n_vars = data.shape\n",
    "    K = 2\n",
    "    net = {}\n",
    "\n",
    "    for i in range(n_vars):\n",
    "        y = data[:,i]\n",
    "        if entropy(y)==0:\n",
    "            net[i] = {\"regs\": [], \"expr\":\"%d\"%y[0], \"acc\":1.0}\n",
    "            continue\n",
    "\n",
    "        W = [j for j in range(n_vars) if j!=i]\n",
    "        for k in range(1,K+1):\n",
    "            S = MIFS(y, W, data, k)\n",
    "            S_swapped,_ = SWAP(y, S, [w for w in W if w not in S], data)\n",
    "            pats = data[:, S_swapped]\n",
    "            expr, fn, acc = fit_allowed_logic(y, pats)\n",
    "            # remap v1/v2/v tokens\n",
    "            if expr not in (\"0\",\"1\"):\n",
    "                if len(S_swapped)==1:\n",
    "                    expr = expr.replace(\"v\", f\"v{S_swapped[0]}\")\n",
    "                else:\n",
    "                    expr = expr.replace(\"v1\", f\"v{S_swapped[0]}\")\n",
    "                    expr = expr.replace(\"v2\", f\"v{S_swapped[1]}\")\n",
    "            if acc>=1-1e-9 or k==K:\n",
    "                net[i] = {\"regs\":S_swapped, \"expr\":expr, \"acc\":acc}\n",
    "                break\n",
    "\n",
    "    # pretty‐print\n",
    "    for i in sorted(net):\n",
    "        entry = net[i]\n",
    "        print(f\"v{i} = {entry['expr']}   \")\n",
    "\n",
    "    return net\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Example on your 7‐node simulated data\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    def update_7(s):\n",
    "        v0,v1,v2,v3,v4,v5,v6 = s\n",
    "        return np.array([\n",
    "            v1 and not v2,\n",
    "            v0 or v3,\n",
    "            not v4,\n",
    "            v2 or not v5,\n",
    "            v3 and v6,\n",
    "            not v1 or v4,\n",
    "            v5 and not v0\n",
    "        ],dtype=int)\n",
    "\n",
    "    state = np.random.randint(0,2,7)\n",
    "    traj  = np.zeros((50,7), int)\n",
    "    for t in range(50):\n",
    "        traj[t] = state\n",
    "        state = update_7(state)\n",
    "\n",
    "    infer_boolean_network_restricted(traj)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECISION TREE CLASSIFIER INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0 = (NOT v5 AND v6)    \n",
      "v1 = (NOT v2 AND v5) OR (v2 AND NOT v5) OR (v2 AND v5)    \n",
      "v2 = (NOT v1 AND v4 AND v5) OR (v1 AND NOT v4 AND NOT v5) OR (v1 AND v4 AND NOT v5) OR (v1 AND v4 AND v5)    \n",
      "v3 = (NOT v0 AND NOT v1) OR (NOT v0 AND v1) OR (v0 AND NOT v1)    \n",
      "v4 = (v2 AND v3 AND v5)    \n",
      "v5 = (NOT v0 AND NOT v2 AND NOT v4) OR (NOT v0 AND NOT v2 AND v4) OR (NOT v0 AND v2 AND v4)    \n",
      "v6 = (v0 AND NOT v2) OR (v0 AND v2)    \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def infer_boolean_network_dt_unrestrained(data, max_depth=None):\n",
    "    \"\"\"\n",
    "    Unrestricted decision-tree inference of a Boolean network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray, shape (n_samples, n_vars)\n",
    "        Binary (0/1) expression states.\n",
    "    max_depth : int or None\n",
    "        Passed to DecisionTreeClassifier; None grows until pure leaves.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    network : dict\n",
    "      target_idx -> {\n",
    "        'regs':        [j,k,…],                 # regulator indices\n",
    "        'truth_table': {pattern:bit,…},         # full lookup\n",
    "        'accuracy':    float                    # training accuracy (==1.0)\n",
    "      }\n",
    "    \"\"\"\n",
    "    n_samples, n_vars = data.shape\n",
    "    network = {}\n",
    "\n",
    "    for i in range(n_vars):\n",
    "        # prepare features/target\n",
    "        X = np.delete(data, i, axis=1)\n",
    "        y = data[:, i]\n",
    "\n",
    "        # train unrestricted tree\n",
    "        clf = DecisionTreeClassifier(max_depth=max_depth)\n",
    "        clf.fit(X, y)\n",
    "\n",
    "        # find which feature columns were used in the splits\n",
    "        used_feats = sorted({f for f in clf.tree_.feature if f >= 0})\n",
    "        # map back to original variable indices\n",
    "        regs = [(f if f < i else f + 1) for f in used_feats]\n",
    "\n",
    "        # build the exact truth table over those regulators\n",
    "        truth_table = {}\n",
    "        for pattern in product([0, 1], repeat=len(regs)):\n",
    "            # build a single‐row input to predict()\n",
    "            row = np.zeros((1, n_vars - 1), dtype=int)\n",
    "            for bit, orig_idx in zip(pattern, regs):\n",
    "                feat_idx = orig_idx if orig_idx < i else orig_idx - 1\n",
    "                row[0, feat_idx] = bit\n",
    "            truth_table[pattern] = int(clf.predict(row)[0])\n",
    "\n",
    "        # compute accuracy on the original data\n",
    "        preds = clf.predict(X)\n",
    "        accuracy = float(np.mean(preds == y))\n",
    "\n",
    "        network[i] = {\n",
    "            'regs': regs,\n",
    "            'truth_table': truth_table,\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "\n",
    "    return network\n",
    "\n",
    "def pretty_print_network(network):\n",
    "    \"\"\"\n",
    "    Given the network dict from above, print each node as:\n",
    "      v0 = (NOT v2 AND v1) OR (v2 AND NOT v1) OR …\n",
    "    \"\"\"\n",
    "    for i in sorted(network):\n",
    "        info = network[i]\n",
    "        regs = info['regs']\n",
    "        table = info['truth_table']\n",
    "\n",
    "        # collect all minterms mapping to 1\n",
    "        terms = []\n",
    "        for pat, out in table.items():\n",
    "            if out == 1:\n",
    "                lits = []\n",
    "                for bit, r in zip(pat, regs):\n",
    "                    if bit:\n",
    "                        lits.append(f\"v{r}\")\n",
    "                    else:\n",
    "                        lits.append(f\"NOT v{r}\")\n",
    "                terms.append(\"(\" + \" AND \".join(lits) + \")\")\n",
    "\n",
    "        expr = \" OR \".join(terms) if terms else \"0\"\n",
    "        print(f\"v{i} = {expr}    \")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# Example usage on your 7-node trajectory `traj`:\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    # assume `traj` is (T×7) ground-truth data you already have\n",
    "    net_dt_unres = infer_boolean_network_dt_unrestrained(traj, max_depth=None)\n",
    "    pretty_print_network(net_dt_unres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_network = '''v0 = v1 AND NOT v2 \n",
    "    v1 = v0 OR v3 \n",
    "    v2 = NOT v4 \n",
    "    v3 = v2 OR NOT v5 \n",
    "    v4 = v3 AND v6 \n",
    "    v5 = NOT v1 OR v4 \n",
    "    v6 = v5 AND NOT v0'''\n",
    "\n",
    "mibni_network = '''v0 = v3 AND NOT v3   \n",
    "    v1 = 1   \n",
    "    v2 = NOT v0 AND v3   \n",
    "    v3 = NOT v0 OR v5   \n",
    "    v4 = v6   \n",
    "    v5 = NOT v3 AND v3   \n",
    "    v6 = v4  '''\n",
    "\n",
    "dt_network = '''v0 = (NOT v3)    \n",
    "v1 = ()    \n",
    "v2 = (NOT v5)    \n",
    "v3 = (NOT v0)    \n",
    "v4 = 0    \n",
    "v5 = (NOT v2 AND NOT v4 AND NOT v6) OR (NOT v2 AND NOT v4 AND v6) OR (NOT v2 AND v4 AND NOT v6) OR (NOT v2 AND v4 AND v6)    \n",
    "v6 = (NOT v3 AND NOT v4 AND NOT v5) OR (NOT v3 AND NOT v4 AND v5) OR (NOT v3 AND v4 AND NOT v5) OR (NOT v3 AND v4 AND v5) '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Topology similarity ===\n",
      "MIBNI: {'precision': 0.25, 'recall': 0.15384615384615385, 'f1': 0.1904761904761905, 'avg_jaccard': 0.11904761904761904, 'per_jaccard': {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.3333333333333333, 4: 0.5, 5: 0.0, 6: 0.0}}\n",
      "   DT: {'precision': 0.2222222222222222, 'recall': 0.15384615384615385, 'f1': 0.18181818181818185, 'avg_jaccard': 0.07142857142857142, 'per_jaccard': {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.25, 6: 0.25}}\n",
      "\n",
      "=== Trajectory similarity (fraction matching) ===\n",
      "MIBNI vs GT: 0.834\n",
      "DT   vs GT: 0.506\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Your network strings\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "gt_network = '''v0 = v1 AND NOT v2 \n",
    "v1 = v0 OR v3 \n",
    "v2 = NOT v4 \n",
    "v3 = v2 OR NOT v5 \n",
    "v4 = v3 AND v6 \n",
    "v5 = NOT v1 OR v4 \n",
    "v6 = v5 AND NOT v0'''\n",
    "\n",
    "mibni_network = '''v0 = v3 AND NOT v3   \n",
    "v1 = 1   \n",
    "v2 = NOT v0 AND v3   \n",
    "v3 = NOT v0 OR v5   \n",
    "v4 = v6   \n",
    "v5 = NOT v3 AND v3   \n",
    "v6 = v4'''\n",
    "\n",
    "dt_network = '''v0 = (NOT v3)    \n",
    "v1 = ()    \n",
    "v2 = (NOT v5)    \n",
    "v3 = (NOT v0)    \n",
    "v4 = 0    \n",
    "v5 = (NOT v2 AND NOT v4 AND NOT v6) OR (NOT v2 AND NOT v4 AND v6) OR (NOT v2 AND v4 AND NOT v6) OR (NOT v2 AND v4 AND v6)    \n",
    "v6 = (NOT v3 AND NOT v4 AND NOT v5) OR (NOT v3 AND NOT v4 AND v5) OR (NOT v3 AND v4 AND NOT v5) OR (NOT v3 AND v4 AND v5) '''\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2) Parser: turn string → dict with 'regs' and 'truth_table'\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def parse_network(network_str):\n",
    "    net = {}\n",
    "    lines = network_str.strip().splitlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line: \n",
    "            continue\n",
    "        left, right = line.split('=', 1)\n",
    "        var = left.strip()\n",
    "        i = int(re.match(r'v(\\d+)', var).group(1))\n",
    "        expr_str = right.strip()\n",
    "        # find regulators\n",
    "        regs = sorted({int(n) for n in re.findall(r'v(\\d+)', expr_str)})\n",
    "        # prepare Python‐style boolean expression\n",
    "        expr_py = expr_str.replace('AND', 'and').replace('OR', 'or').replace('NOT', 'not')\n",
    "        # build truth table\n",
    "        truth_table = {}\n",
    "        for pattern in product([0,1], repeat=len(regs)):\n",
    "            env = {f'v{r}': pattern[idx] for idx, r in enumerate(regs)}\n",
    "            val = eval(expr_py, {}, env)\n",
    "            truth_table[tuple(pattern)] = int(bool(val))\n",
    "        net[i] = {\n",
    "            'regs': regs,\n",
    "            'truth_table': truth_table\n",
    "        }\n",
    "    return net\n",
    "\n",
    "# parse all three\n",
    "net_true  = parse_network(gt_network)\n",
    "net_mibni = parse_network(mibni_network)\n",
    "net_dt    = parse_network(dt_network)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 3) Topology similarity\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def topology_similarity(net_true, net_pred):\n",
    "    edges_true = {(j,i) for i,info in net_true.items() for j in info['regs']}\n",
    "    edges_pred = {(j,i) for i,info in net_pred.items() for j in info['regs']}\n",
    "    TP = edges_true & edges_pred\n",
    "    prec = len(TP)/len(edges_pred) if edges_pred else 0.0\n",
    "    rec  = len(TP)/len(edges_true)  if edges_true  else 0.0\n",
    "    f1   = 2*prec*rec/(prec+rec)     if (prec+rec)>0 else 0.0\n",
    "    # per‐node Jaccard\n",
    "    per_j = {}\n",
    "    for i in net_true:\n",
    "        S_true = set(net_true[i]['regs'])\n",
    "        S_pred = set(net_pred[i]['regs'])\n",
    "        U = S_true | S_pred\n",
    "        per_j[i] = len(S_true & S_pred)/len(U) if U else 1.0\n",
    "    return {\n",
    "        'precision': prec,\n",
    "        'recall':    rec,\n",
    "        'f1':        f1,\n",
    "        'avg_jaccard': np.mean(list(per_j.values())),\n",
    "        'per_jaccard': per_j\n",
    "    }\n",
    "\n",
    "# compute topology scores\n",
    "topo_mibni = topology_similarity(net_true, net_mibni)\n",
    "topo_dt    = topology_similarity(net_true, net_dt)\n",
    "\n",
    "print(\"=== Topology similarity ===\")\n",
    "print(\"MIBNI:\", topo_mibni)\n",
    "print(\"   DT:\", topo_dt)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 4) Trajectory similarity\n",
    "#    assumes you have a NumPy array `traj` of shape (T, n_vars)\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "def make_update_fn(network, n_vars):\n",
    "    def update(state):\n",
    "        new = np.zeros(n_vars, dtype=int)\n",
    "        for i, info in network.items():\n",
    "            regs = info['regs']\n",
    "            if regs:\n",
    "                pat = tuple(state[j] for j in regs)\n",
    "                new[i] = info['truth_table'][pat]\n",
    "            else:\n",
    "                new[i] = next(iter(info['truth_table'].values()))\n",
    "        return new\n",
    "    return update\n",
    "\n",
    "def simulate_network(update_fn, initial_state, steps):\n",
    "    n_vars = len(initial_state)\n",
    "    traj_pred = np.zeros((steps, n_vars), dtype=int)\n",
    "    state = initial_state.copy()\n",
    "    for t in range(steps):\n",
    "        traj_pred[t] = state\n",
    "        state = update_fn(state)\n",
    "    return traj_pred\n",
    "\n",
    "def trajectory_similarity(traj_true, traj_pred):\n",
    "    return np.mean(traj_true == traj_pred)\n",
    "\n",
    "# run trajectory comparison\n",
    "init   = traj[0]\n",
    "steps  = traj.shape[0]\n",
    "n_vars = traj.shape[1]\n",
    "\n",
    "upd_mibni = make_update_fn(net_mibni, n_vars)\n",
    "upd_dt    = make_update_fn(net_dt,    n_vars)\n",
    "\n",
    "traj_mibni = simulate_network(upd_mibni, init, steps)\n",
    "traj_dt    = simulate_network(upd_dt,    init, steps)\n",
    "\n",
    "sim_mibni = trajectory_similarity(traj, traj_mibni)\n",
    "sim_dt    = trajectory_similarity(traj, traj_dt)\n",
    "\n",
    "print(\"\\n=== Trajectory similarity (fraction matching) ===\")\n",
    "print(f\"MIBNI vs GT: {sim_mibni:.3f}\")\n",
    "print(f\"DT   vs GT: {sim_dt:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node v0 train‐accuracy = 1.000\n",
      "node v1 train‐accuracy = 1.000\n",
      "node v2 train‐accuracy = 1.000\n",
      "node v3 train‐accuracy = 1.000\n",
      "node v4 train‐accuracy = 0.980\n",
      "node v5 train‐accuracy = 1.000\n",
      "node v6 train‐accuracy = 0.980\n",
      "=== Topology similarity (unrestr DT) === {'precision': 0.3333333333333333, 'recall': 0.46153846153846156, 'f1': 0.3870967741935484, 'avg_jaccard': 0.24999999999999997, 'per_jaccard': {0: 0.0, 1: 0.3333333333333333, 2: 0.3333333333333333, 3: 0.0, 4: 0.25, 5: 0.5, 6: 0.3333333333333333}}\n",
      "=== Trajectory similarity (unrestr DT) === 0.44\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# (paste in the infer_boolean_network_dt_unrestrained and make_update_fn,\n",
    "#  topology_similarity, simulate_network, trajectory_similarity from before)\n",
    "\n",
    "# 1) Generate your GT trajectory `traj` as you already have:\n",
    "#    traj.shape == (T, 7)\n",
    "\n",
    "# 2) Parse the GT string into net_true\n",
    "net_true = parse_network(gt_network)   # your ground‐truth parser\n",
    "\n",
    "# 3) Infer the **unrestrained** DT network directly from the raw traj data:\n",
    "net_dt_unres = infer_boolean_network_dt_unrestrained(traj, max_depth=None)\n",
    "\n",
    "# 4) Check that every node was fit perfectly on training:\n",
    "for i,info in net_dt_unres.items():\n",
    "    print(f\"node v{i} train‐accuracy = {info['accuracy']:.3f}\")\n",
    "# You should see 1.000 for all i.\n",
    "\n",
    "# 5) Now recompute similarities **directly** on the dicts:\n",
    "topo_dt    = topology_similarity(net_true, net_dt_unres)\n",
    "\n",
    "# 6) Simulate from the same initial state:\n",
    "init   = traj[0]\n",
    "steps  = traj.shape[0]\n",
    "n_vars = traj.shape[1]\n",
    "\n",
    "upd_dt    = make_update_fn(net_dt_unres, n_vars)\n",
    "traj_dt   = simulate_network(upd_dt, init, steps)\n",
    "\n",
    "sim_dt    = trajectory_similarity(traj, traj_dt)\n",
    "\n",
    "print(\"=== Topology similarity (unrestr DT) ===\", topo_dt)\n",
    "print(\"=== Trajectory similarity (unrestr DT) ===\", sim_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First mismatch at step 1, node v0:\n",
      "  GT: 0   DT: 1\n",
      "  Regulators for v0: [5, 6]\n",
      "  Pattern at t-1: (0, 1)\n",
      "  DT lookup gives: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# find the first mismatch\n",
    "mm = np.argwhere(traj != traj_dt)\n",
    "if mm.size == 0:\n",
    "    print(\"Perfect match!\")\n",
    "else:\n",
    "    t0, node = mm[0]\n",
    "    print(f\"First mismatch at step {t0}, node v{node}:\")\n",
    "    print(\"  GT:\", traj[t0,node], \"  DT:\", traj_dt[t0,node])\n",
    "\n",
    "    # see the regulator‐pattern that caused it\n",
    "    regs = net_dt_unres[node]['regs']\n",
    "    prev_state = traj_dt[t0-1]\n",
    "    pat = tuple(prev_state[j] for j in regs)\n",
    "    print(\"  Regulators for v{}: {}\".format(node, regs))\n",
    "    print(\"  Pattern at t-1:\", pat)\n",
    "    print(\"  DT lookup gives:\", net_dt_unres[node]['truth_table'][pat])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
